/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
  
  "clients.baml": "client<llm> GPT4 {\n  provider openai\n  options {\n    model \"gpt-4\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> Claude {\n  provider anthropic\n  options {\n    model \"claude-3-opus-20240229\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> FastAnthropic {\n  provider anthropic\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> FastOpenAI {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n\nclient<llm> Fast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [FastAnthropic, FastOpenAI]\n  }\n}\n\nclient<llm> Openai {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [GPT4, FastOpenAI]\n  }\n}",
  "generators.baml": "\n// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\"\n    output_type \"typescript/react\"\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.86.1\"\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    // Regardless of this setting, you can always explicitly call either of the following:\n    // - b.sync.FunctionName()\n    // - b.async_.FunctionName() (note the underscore to avoid a keyword conflict)\n    default_client_mode async\n}",
  "prompt.baml": "class Story {\n  title string @stream.not_null\n  content string @stream.not_null\n}\n\nfunction WriteMeAStory(input: string) -> Story {\n  client \"openai/gpt-4o\"\n  prompt #\"\n    Tell me a short story\n\n    {{ ctx.output_format() }}\n\n    {{ _.role(\"user\") }}\n\n    Topic: {{input}}\n  \"#\n}\n\n//test the writemeastory function\ntest test_write_me_a_story {\n  functions [WriteMeAStory]\n  args {\n    input #\"\n\n        A cat and a dog become friends\n\n        A bird learns to fly\n    \"#\n  }\n}\n",
  "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n\n\n\n// Creating a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  client GPT4\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Testing the function with a sample resume.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}